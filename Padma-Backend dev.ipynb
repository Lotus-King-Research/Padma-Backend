{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbc82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildPadmaIndex:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 read_from_file=None,\n",
    "                 tokens_path=None,\n",
    "                 max_files=False):\n",
    "    \n",
    "        '''Build Padma index either from previously created index \n",
    "        stored in a file or by creating a new index from texts.\n",
    "            \n",
    "        read_from_file | bool | either None or the prefix of the filename used when\n",
    "        max_files | int | to make debugging faster\n",
    "        '''\n",
    "    \n",
    "        if read_from_file is None and tokens_path is None:\n",
    "            raise(ValueError('read_from_file and tokens_path can not both be None'))\n",
    "    \n",
    "        self._tokens_path = tokens_path\n",
    "    \n",
    "        # for debugging cases\n",
    "        self._max_files = max_files\n",
    "        \n",
    "        # filename is provided as string\n",
    "        if isinstance(read_from_file, str):\n",
    "            self._null = self._read_from_file(read_from_file)\n",
    "        \n",
    "        # default input value None is provided\n",
    "        elif read_from_file is None:\n",
    "            self._null = self._generate_text_index()\n",
    "        \n",
    "        # something else is provided\n",
    "        else:\n",
    "            raise(ValueError('read_from_file` must be either None or a string that points to a file name.'))\n",
    "        \n",
    "    def _read_from_file(self, name):\n",
    "        \n",
    "        '''For the case where index is already created previously.'''\n",
    "        \n",
    "        import pickle\n",
    "     \n",
    "        with open(name + '-main_index.pkl', 'rb') as f:\n",
    "            self.final_index = pickle.load(f)\n",
    "            \n",
    "        with open(name + '-id_to_file.pkl', 'rb') as f:\n",
    "            self.id_to_file = pickle.load(f)\n",
    "        \n",
    "    def _generate_text_index(self):\n",
    "\n",
    "        '''For the case where new index is to be created.'''\n",
    "        \n",
    "        from tqdm import tqdm\n",
    "        import glob\n",
    "        import gzip\n",
    "        import os\n",
    "        import re\n",
    "        \n",
    "        # get names of files for tokens\n",
    "        files = glob.iglob(self._tokens_path + '**/*.*', recursive=True)\n",
    "        files = list(files)\n",
    "    \n",
    "        # limit based on max files\n",
    "        if self._max_files is not False:\n",
    "            files = files[:self._max_files]\n",
    "\n",
    "        # decompress and rename if gz\n",
    "        for i, filename in enumerate(files): \n",
    "            if filename.endswith('.gz'):\n",
    "                os.system('gzip -d ' + filename)\n",
    "            files[i] = re.sub('\\.gz$', '', filename)        \n",
    "            \n",
    "        # read tokens into memory\n",
    "        tokens = {}\n",
    "        for file in files:\n",
    "\n",
    "            try:\n",
    "                tokens[file] = open(file, 'r').read().split()\n",
    "            except AttributeError:\n",
    "                tokens[file] = []\n",
    "\n",
    "        # create list of all unique tokens\n",
    "        out = []\n",
    "        for file in files:\n",
    "            temp_tokens = tokens[file]\n",
    "            out += temp_tokens\n",
    "        word_list = list(set(out))\n",
    "\n",
    "        # create file-to-id indexes\n",
    "        self.file_to_id = {}\n",
    "        self.id_to_file = {}\n",
    "        for i, file in enumerate(files):\n",
    "            self.file_to_id[file] = i\n",
    "            self.id_to_file[i] = file\n",
    "\n",
    "        # put everything together\n",
    "        self.final_index = {}\n",
    "        self.word_set = set(word_list)\n",
    "\n",
    "        # create key values\n",
    "        for word in self.word_set:\n",
    "            self.final_index[word] = {}\n",
    "\n",
    "        # create values\n",
    "        for file in tqdm(files):  \n",
    "            text_set = set(tokens[file])\n",
    "            \n",
    "            for word in self.word_set.intersection(text_set):\n",
    "                \n",
    "                self.final_index[word][self.file_to_id[file]] = []\n",
    "            \n",
    "                #locations = list(filter(lambda x: tokens[file][x] == word, range(len(tokens[file]))))\n",
    "                \n",
    "                ## experimental ##\n",
    "                \n",
    "                locations = []\n",
    "                \n",
    "                for i, fragment in enumerate(''.join(tokens[file]).split('_')):\n",
    "                    if word in fragment:\n",
    "                        locations += [i]\n",
    "                \n",
    "                ## experimental ends) ##\n",
    "                \n",
    "                self.final_index[word][self.file_to_id[file]] += locations\n",
    "                      \n",
    "    def word_to_text(self, word):\n",
    "        \n",
    "        out = []\n",
    "        \n",
    "        for text_id in self.final_index[word].keys():\n",
    "    \n",
    "            file = self.id_to_file[text_id]\n",
    "            text = open(file, 'r').read()\n",
    "            \n",
    "            out.append([file, text])\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def word_to_location(self, word):\n",
    "        \n",
    "        out = []\n",
    "        \n",
    "        for text_id in self.final_index[word].keys():\n",
    "            \n",
    "            location = [[text_id, i] for i in self.final_index[word][text_id]]\n",
    "            \n",
    "            out.append(location)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def save_to_file(self, name):\n",
    "        \n",
    "        import pickle\n",
    "        from sqlitedict import SqliteDict\n",
    "        \n",
    "        index = SqliteDict(name + '-main_index.sqlite', autocommit=True)\n",
    "        for key in temp_index.final_index.keys():\n",
    "            index[key] = temp_index.final_index[key]\n",
    "        \n",
    "        with open(name + '-id_to_file.pkl', 'wb') as f:\n",
    "            pickle.dump(self.id_to_file, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78889a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████████████████                                                           | 7/14 [01:16<01:03,  9.10s/it]"
     ]
    }
   ],
   "source": [
    "index = BuildPadmaIndex(tokens_path='/Users/upstairs/dev/tokens/')\n",
    "#index.save_to_file('Padma-Index')\n",
    "#temp_index = BuildPadmaIndex(read_from_file='Padma-Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93860379",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.word_to_text('སླེབ')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d7ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9800422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/Users/upstairs/dev/Padma-Backend/app/data/title_info.pkl', 'rb') as f:\n",
    "    titles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1283fb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ངོ་མཚར་སྤྲུལ་པའི་སྐུ་མཆོག་རིས་མེད་གཏེར་སྟོན་རིམ་པར་བྱོན་པ་རྣམས་ཀྱི་གསོལ་འདེབས་རྒྱས་པར་བཀོད་པ་མོས་གུས་རྒྱ་མཚོའི་རླབས་ཕྲེང་',\n",
       " 'Author': 'འཇམ་མགོན་ཀོང་སྤྲུལ་',\n",
       " 'Terdzö Category': 'Lineage Histories',\n",
       " 'Tibetan Colophon(s)': 'ཅེས་རྒྱལ་དབང་པདྨཱ་ཀ་རའི་ཕྲིན་ལས་ཀྱི་གཙོ་བོ་རྡོ་རྗེའི་གསུང་གི་གསང་བ་ཟབ་མོ་རིན་ཆེན་གཏེར་གྱི་མཛོད་ཆེན་པོ་རྩོལ་བས་སྒྲུབ་པའི་སྐབས་སུ། གཏེར་འབྱུང་གི་རིགས་དང་སོ་སོའི་རྣམ་ཐར་ལས་བྱུང་བ་དང་། གཙོ་བོ་ཁྱབ་བདག་མཚོ་སྐྱེས་རྡོ་རྗེ་དང་ཞལ་མི་གཉིས་པ་ཀུན་མཁྱེན་བླ་མ་རྡོ་རྗེ་གཟི་བརྗིད་ཀྱི་ཞལ་ལུང་ལ་གཞིར་བྱས། །བྱང་བདག་གིས་མཛད་པའི་མཚན་ཡོངས་བསྡམས། བདུད་འདུལ་དང་གནམ་ཆོས་སོགས་ཀྱིས་མཛད་པའི་གཏེར་བརྒྱའི་གསོལ་འདེབས་ལས་མཚན་ཐོ་བྱུང་བས་ཀྱང་ཁ་བསྐངས་ཏེ། པདྨའི་སྔགས་རིག་འཛིན་པ་པདྨ་གར་དབང་ཕྲིན་ལས་འགྲོ་འདུལ་རྩལ་གྱིས་དཔལ་དེ་བཱི་ཀོ་ཊཱིའི་དབེན་ཁྲོད་ཙ་འདྲ་རིན་ཆེན་བྲག་གི་སྒྲུབ་གནས་ཀུན་བཟང་བདེ་ཆེན་འོད་གསལ་གླིང་དུ་སྦྱར་བ་དགེ་ལེགས་འཕེལ།།  །།',\n",
       " 'Links': 'No TBRC link // No THL link'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles['Terdzo-KA-007']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebece2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1736: expected 5 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'https://raw.githubusercontent.com/OpenPecha/catalog/master/data/catalog.csv'\n",
    "openpecha_titles = pd.read_csv(path, error_bad_lines=False)[:4325]\n",
    "\n",
    "def get_id(s):\n",
    "    \n",
    "    s = s.split(']')[0]\n",
    "    s = s.replace('[', '')\n",
    "    \n",
    "    return s\n",
    "    \n",
    "openpecha_titles['ID'] = openpecha_titles.ID.apply(get_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "        with open(name + '-title-info.pkl', 'wb') as f:\n",
    "            pickle.dump(self.id_to_file, f, pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2279779d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09a57582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Author</th>\n",
       "      <th>Source ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bdr:W22083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P000004</td>\n",
       "      <td>བཀའ་འགྱུར། ༼ཧེ་མིས་བྲིས་མ།༽</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bdr:W2KG210298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P000005</td>\n",
       "      <td>བཀའ་འགྱུར། ༼ཕུག་བྲག་བྲིས་མ༽</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bdr:W2KG210295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>P010800</td>\n",
       "      <td>སྟག་འབུམ་རྒྱལ་གྱི་སྒྲུང་གཏམ་ལ་དཔྱད་པ།</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bdr:W1KG25503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>P010801</td>\n",
       "      <td>ཤེར་ཕྱིན་བརྒྱད་སྟོང་པའི་བཤད་པ་མངོན་རྟོགས་རྒྱན་...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bdr:W3CN4869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>P010802</td>\n",
       "      <td>དྲིན་ལན་བསབ་པའི་མདོ།</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bdr:W3CN8173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>P010803</td>\n",
       "      <td>དཔལ་ཀྱེ་རྡོ་རྗེའི་རྒྱུད་ཀྱི་བཤད་པ་བཀའི་བརྒྱ་པ་...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bdr:W29902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>P010804</td>\n",
       "      <td>ཁེད</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bdr:W2DB25437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4325 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                              Title Volume  \\\n",
       "0     P000001                                                NaN    NaN   \n",
       "1     P000002                                                NaN    NaN   \n",
       "2     P000003                                                NaN    NaN   \n",
       "3     P000004                        བཀའ་འགྱུར། ༼ཧེ་མིས་བྲིས་མ།༽    NaN   \n",
       "4     P000005                        བཀའ་འགྱུར། ༼ཕུག་བྲག་བྲིས་མ༽    NaN   \n",
       "...       ...                                                ...    ...   \n",
       "4320  P010800              སྟག་འབུམ་རྒྱལ་གྱི་སྒྲུང་གཏམ་ལ་དཔྱད་པ།    NaN   \n",
       "4321  P010801  ཤེར་ཕྱིན་བརྒྱད་སྟོང་པའི་བཤད་པ་མངོན་རྟོགས་རྒྱན་...    NaN   \n",
       "4322  P010802                               དྲིན་ལན་བསབ་པའི་མདོ།    NaN   \n",
       "4323  P010803  དཔལ་ཀྱེ་རྡོ་རྗེའི་རྒྱུད་ཀྱི་བཤད་པ་བཀའི་བརྒྱ་པ་...    NaN   \n",
       "4324  P010804                                                ཁེད    NaN   \n",
       "\n",
       "     Author       Source ID  \n",
       "0       NaN             NaN  \n",
       "1       NaN             NaN  \n",
       "2       NaN      bdr:W22083  \n",
       "3       NaN  bdr:W2KG210298  \n",
       "4       NaN  bdr:W2KG210295  \n",
       "...     ...             ...  \n",
       "4320    NaN   bdr:W1KG25503  \n",
       "4321    NaN    bdr:W3CN4869  \n",
       "4322    NaN    bdr:W3CN8173  \n",
       "4323    NaN      bdr:W29902  \n",
       "4324    NaN   bdr:W2DB25437  \n",
       "\n",
       "[4325 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openpecha_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de082c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3052738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.iglob('/Users/upstairs/dev/Padma-Tokens/tokens/' + '**/*.*', recursive=True)\n",
    "files = list(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aea0a5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/upstairs/dev/Padma-Tokens/tokens/P008105/v036.txt.gz'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a309611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlitedict import SqliteDict\n",
    "index = SqliteDict('index.sqlite', autocommit=True)\n",
    "for key in temp_index.final_index.keys():\n",
    "    index[key] = temp_index.final_index[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa384ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_index = BuildPadmaIndex(read_from_file='Padma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc91a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec98d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056bc2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "689e542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3369140"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_obj_size(_read_from_file('Padma-main_index.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29172808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Terdzo-TI-046-1.txt',\n",
       " 1: 'Terdzo-PHI-063.txt',\n",
       " 2: 'Terdzo-BI-033.txt',\n",
       " 3: 'Terdzo-ZHI-038.txt',\n",
       " 4: 'Terdzo-TSA-013.txt',\n",
       " 5: 'Terdzo-CI-027.txt',\n",
       " 6: 'Terdzo-BI-027.txt',\n",
       " 7: 'Terdzo-TSA-007.txt',\n",
       " 8: 'Terdzo-PHI-077.txt',\n",
       " 9: 'Terdzo-ZHI-004.txt'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_read_from_file('Padma-id_to_file.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2d48321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_obj_size(obj):\n",
    "\n",
    "    import gc\n",
    "    import sys\n",
    "\n",
    "    marked = {id(obj)}\n",
    "    obj_q = [obj]\n",
    "    sz = 0\n",
    "\n",
    "    while obj_q:\n",
    "        sz += sum(map(sys.getsizeof, obj_q))\n",
    "\n",
    "        # Lookup all the object referred to by the object in obj_q.\n",
    "        # See: https://docs.python.org/3.7/library/gc.html#gc.get_referents\n",
    "        all_refr = ((id(o), o) for o in gc.get_referents(*obj_q))\n",
    "\n",
    "        # Filter object that are already marked.\n",
    "        # Using dict notation will prevent repeated objects.\n",
    "        new_refr = {o_id: o for o_id, o in all_refr if o_id not in marked and not isinstance(o, type)}\n",
    "\n",
    "        # The new obj_q will be the ones that were not marked,\n",
    "        # and we will update marked with their ids so we will\n",
    "        # not traverse them again.\n",
    "        obj_q = new_refr.values()\n",
    "        marked.update(new_refr.keys())\n",
    "\n",
    "    return sz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
